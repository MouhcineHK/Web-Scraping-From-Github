{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fbf9816",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'FirstData.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 96\u001b[0m\n\u001b[0;32m     94\u001b[0m input_csv_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFirstData.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     95\u001b[0m output_csv_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSecondData.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 96\u001b[0m \u001b[43mupdate_csv_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_csv_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_csv_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [1], line 36\u001b[0m, in \u001b[0;36mupdate_csv_file\u001b[1;34m(csv_file, output_csv_file)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_csv_file\u001b[39m(csv_file, output_csv_file):\n\u001b[1;32m---> 36\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcsv_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOpening the input file...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     38\u001b[0m         reader \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mDictReader(file)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'FirstData.csv'"
     ]
    }
   ],
   "source": [
    "#Get more repositories informations\n",
    "#ThreadPoolExecuter\n",
    "tokens = [\n",
    "\"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\" , \n",
    "\"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\" ,\n",
    "\"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\" ,\n",
    "\"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\" ,\n",
    "\"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\",\n",
    "\"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\" ,\n",
    "\"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\" ,\n",
    "\"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\" ,\n",
    "\"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\" ,\n",
    "\"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\" ,\n",
    "\"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\" ,\n",
    "\"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\" \n",
    "]\n",
    "def fetch_languages_url(repo_url, token):\n",
    "    headers = {'Authorization': f'token {token}'}\n",
    "    response = requests.get(repo_url, headers=headers)\n",
    "\n",
    "    remaining_requests = int(response.headers.get('X-RateLimit-Remaining', 0))\n",
    "    reset_time = int(response.headers.get('X-RateLimit-Reset', 0))\n",
    "\n",
    "    if remaining_requests == 0:\n",
    "        remaining_requests = 0  # Reset remaining_requests to indicate rate limit reached\n",
    "        reset_time = time.time() + 1  # Set reset_time to current time + 1 second to force retry\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        repo_data = response.json()\n",
    "        if 'languages_url' in repo_data:\n",
    "            return repo_data['languages_url'], remaining_requests, reset_time\n",
    "\n",
    "    return None, remaining_requests, reset_time\n",
    "\n",
    "def update_csv_file(csv_file, output_csv_file):\n",
    "    with open(csv_file, 'r') as file:\n",
    "        print('Opening the input file...')\n",
    "        reader = csv.DictReader(file)\n",
    "        headers = reader.fieldnames + ['languages_url']\n",
    "        rows = list(reader)\n",
    "\n",
    "    with open(output_csv_file, 'w', newline='') as file:\n",
    "        print('Opening the output file...')\n",
    "        writer = csv.DictWriter(file, fieldnames=headers)\n",
    "        writer.writeheader()\n",
    "\n",
    "        retry_count = 0\n",
    "        token_index = 0\n",
    "        tokens_count = len(tokens)\n",
    "\n",
    "        def process_row(row):\n",
    "            nonlocal retry_count, token_index\n",
    "\n",
    "            repo_url = row['url']\n",
    "            token = tokens[token_index]\n",
    "\n",
    "            while True:\n",
    "                languages_url, remaining_requests, reset_time = fetch_languages_url(repo_url, token)\n",
    "\n",
    "                if languages_url is not None or remaining_requests > 0:\n",
    "                    break\n",
    "\n",
    "                retry_count += 1\n",
    "                if retry_count == tokens_count:\n",
    "                    print('Rate limit exceeded for all tokens. Saving the retrieved info and exiting...')\n",
    "                    return\n",
    "                else:\n",
    "                    token_index = (token_index + 1) % tokens_count\n",
    "                    token = tokens[token_index]\n",
    "                    print(f'Rate limit exceeded. Switching to the next token (Attempt {retry_count + 1})...')\n",
    "                    print(f'Switching to token index: {token_index}')\n",
    "\n",
    "            row['languages_url'] = languages_url\n",
    "            writer.writerow(row)\n",
    "\n",
    "            # Log progress\n",
    "            repo_url = row['url']\n",
    "            if languages_url is not None:\n",
    "                print(f'Success: Scraped languages URL for repository: {repo_url}')\n",
    "            else:\n",
    "                print(f'Failure: Failed to scrape languages URL for repository: {repo_url}')\n",
    "\n",
    "            if (index + 1) % 950 == 0:\n",
    "                print('Sleeping for 1 minute...')\n",
    "                time.sleep(60)  # Sleep for 1 minute after every 950 processed repos\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "            for index, row in enumerate(rows):\n",
    "                executor.submit(process_row, row)\n",
    "\n",
    "        print('All repositories processed successfully.')\n",
    "\n",
    "# Example usage\n",
    "input_csv_file = 'FirstData.csv'\n",
    "output_csv_file = 'SecondData.csv'\n",
    "update_csv_file(input_csv_file, output_csv_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bd2c86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
